import os, time, re, json
import numpy as np
from numpy.linalg import norm
from openai import OpenAI
from supabase import create_client, Client
from fastapi import FastAPI

# ========== SUPABASE CONNECT ==========
SUPABASE_URL = os.getenv("SUPABASE_URL")
SUPABASE_KEY = os.getenv("SUPABASE_KEY")
supabase: Client = create_client(SUPABASE_URL, SUPABASE_KEY)

# ========== OPENAI CONNECT ==========
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_KEY)

# ========== PRAGJET ==========
GREEN_TH  = 0.70
YELLOW_TH = 0.60
RED_TH    = 0.50  # poshtÃ« 0.50 eliminohen

app_api = FastAPI()

# ========== FUNKSIONE ==========
def cosine(a, b):
    na, nb = norm(a), norm(b)
    if na == 0 or nb == 0:
        return 0.0
    return float(np.dot(a, b) / (na * nb))

def scale01(x):
    return max(0.0, min(1.0, (x + 1.0) / 2.0))

def gpt_check(service_name, query):
    pr = f'A Ã«shtÃ« shÃ«rbimi "{service_name}" i pÃ«rshtatshÃ«m pÃ«r "{query}"? Kthe vetÃ«m: po/jo'
    try:
        r = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": pr}],
            temperature=0, max_tokens=3
        )
        return r.choices[0].message.content.strip().lower() == "po"
    except:
        return False

# ========== ENDPOINT SEARCH ==========
@app_api.get("/search")
def search_service(q: str):
    t0 = time.time()

    # PastrojmÃ« queryn pa e ndryshuar kuptimin
    cleaned = re.sub(r"[^a-zA-Z0-9 Ã«Ã§]+", "", q.lower()).strip()
    refined = cleaned  # nuk e ndryshojmÃ« mÃ« asnjÃ«herÃ« inputin

    # Marrim embedding_large tÃ« query
    rsp = client.embeddings.create(model="text-embedding-3-large", input=refined)
    qemb = np.array(rsp.data[0].embedding, dtype=np.float32)

    # LexojmÃ« embedding_large nga supabase column: "embedding_large"
    rows = supabase.from_("detailedtable").select("id,name,embedding_large,keywords,category").execute().data

    scored = []
    for r in rows:
        if r.get("embedding_large") is None:
            continue
        emb = np.array(r["embedding_large"], dtype=np.float32)
        sim = cosine(qemb, emb)
        sim01 = scale01(sim)

        # eliminojmÃ« poshtÃ« 0.5 sepse sâ€™janÃ« relevante
        if sim01 < RED_TH:
            continue

        # ruajmÃ« vetÃ«m ato qÃ« kanÃ« shans â‰¥0.5
        scored.append((sim01, sim, r))

    # i rendisim sipas relevancÃ«s
    scored.sort(key=lambda x: x[0], reverse=True)

    # marrim max 4 shÃ«rbime
    final = []
    accepted = []
    greens = [x for x in scored if x[0] >= GREEN_TH]
    yellows = [x for x in scored if YELLOW_TH <= x[0] < GREEN_TH]

    # ðŸ‘‰ CASE 1: Nese ka tÃ« paktÃ«n 1 GREEN
    if greens:
        for g in greens[:4]:
            accepted.append(g)
        # NÃ«se ka vetÃ«m 1 ose 2 greens â†’ bÃ«jmÃ« GPT-check vetem pÃ«r njÃ« yellow
        if len(accepted) < 3 and yellows:
            third = yellows[0]
            if gpt_check(third[2]["name"], refined):
                accepted.append(third)

        accepted = accepted[:4]  # max 4
    else:
        # ðŸ‘‰ CASE 2: Nese nuk ka GREEN, por ka YELLOW
        for y in yellows[:2]:
            accepted.append(y)
        # Nese eshte i treti, e kontrollojmÃ« me GPT
        if len(scored) >= 3:
            cand = scored[2]
            if YELLOW_TH <= cand[0] < GREEN_TH:
                if gpt_check(cand[2]["name"], refined):
                    accepted.append(cand)

    for sc, raw, s in accepted:
        final.append({
            "uniqueid": s["id"],  # lidhja me Bubble/Supabase bÃ«het me id
            "name": s["name"],
            "score": round(sc, 3)
        })

    t_total = time.time() - t0
    return {"results": final, "time_sec": round(t_total, 2)}

# ========= RUAJMÃ‹ APP =========
app = app_api
